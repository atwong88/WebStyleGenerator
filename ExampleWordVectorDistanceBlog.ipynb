{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "#model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300-SLIM.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.similarities import WmdSimilarity\n",
    "import pickle\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.query import BatchStatement\n",
    "from cassandra import ConsistencyLevel\n",
    "cluster = Cluster(['127.0.0.1'])#Cluster(['199.60.17.32','199.60.17.65'])\n",
    "session = cluster.connect('mcanute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/matt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "stop_words = stopwords.words('english')\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/matt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')  # Download data for tokenizer.\n",
    "\n",
    "def preprocess(doc):\n",
    "    doc = doc.lower()  # Lower the text.\n",
    "    doc = word_tokenize(doc)  # Split into words.\n",
    "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
    "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('websites/ParsedWebsitesCleanSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * from Blogs;\"\n",
    "data = pd.DataFrame(list(session.execute(query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna() # !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['body_text'].apply(len)>2] ## !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_corpus = data['body_text'].apply(preprocess).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = WmdSimilarity(wmd_corpus, model2, num_best=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(instance,open('WordMoverDistance-BlogInstanceSLIM.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = pickle.load(open('WordMoverDistance-Instance.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_text(val):\n",
    "    if val:\n",
    "        reg = re.compile(r'\\b\\w{3,20}\\b')\n",
    "        temp = reg.findall(val)\n",
    "        temp_set = set(temp)\n",
    "        temp_list = list(temp_set)\n",
    "        if len(temp_list) < 20:\n",
    "            temp2 = temp_list\n",
    "        elif len(temp_list) < 50:\n",
    "            temp2 = temp_list[10:]\n",
    "        elif len(temp_list) < 100:\n",
    "            temp2 = temp_list[30:]\n",
    "        else:\n",
    "            temp2 = temp_list[50:100]\n",
    "        result = \" \".join(temp2) \n",
    "        return (\"...\" + result + \"....\")\n",
    "    else:\n",
    "        return \"Empty string found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>back_color</th>\n",
       "      <th>body_font</th>\n",
       "      <th>body_text</th>\n",
       "      <th>last_update</th>\n",
       "      <th>link_color</th>\n",
       "      <th>text_color</th>\n",
       "      <th>title_font</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://lebleurenard.tumblr.com/</td>\n",
       "      <td>#4ad791</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>Please send me asks ❤️ Moodboard for nights a...</td>\n",
       "      <td>2019-12-03 21:34:55</td>\n",
       "      <td>#A77DC2</td>\n",
       "      <td>#444444</td>\n",
       "      <td>Clarendon Text Pro</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            website back_color       body_font  \\\n",
       "0  https://lebleurenard.tumblr.com/    #4ad791  Helvetica Neue   \n",
       "\n",
       "                                           body_text         last_update  \\\n",
       "0   Please send me asks ❤️ Moodboard for nights a... 2019-12-03 21:34:55   \n",
       "\n",
       "  link_color text_color          title_font title_text  \n",
       "0    #A77DC2    #444444  Clarendon Text Pro             "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityQuery(description):  # !!!\n",
    "    description = description.replace('data', '')\n",
    "    query = preprocess(description)\n",
    "    sims = instance[query]  # A query is simply a \"look-up\" in the similarity class.\n",
    "\n",
    "    # Print the query and the retrieved documents, together with their similarities.\n",
    "    results = []\n",
    "    print(description)\n",
    "    for i in range(3):\n",
    "\n",
    "        row = []\n",
    "        row.append(documents[sims[i][0]][0]) # Website\n",
    "        row.append(documents[sims[i][0]][1]) # Back_Color\n",
    "        row.append(documents[sims[i][0]][5]) # Link_Color\n",
    "        row.append(documents[sims[i][0]][6]) # Text_Color\n",
    "        row.append(documents[sims[i][0]][7]) # Title_Font\n",
    "        row.append(documents[sims[i][0]][2]) # Body_Font\n",
    "        \n",
    "        row.append(documents[sims[i][0]][3]) # Text\n",
    "        \n",
    "        row.append(sims[i][1])    # Similarity\n",
    "\n",
    "\n",
    "        results.append(row)\n",
    "    resultsDF = pd.DataFrame(results)\n",
    "\n",
    "    resultsDF.columns = ['Website','BackColor','LinkColor','TextColor','TitleFont','BodyFont','Text','Similarity']\n",
    "    #resultsDF['Fonts'] = resultsDF['Fonts'].replace({'\\\" \\'': '\\\", \\'', \"\\' \\'\": \"\\', \\'\", '(\\r\\n)': ','}, regex=True)\n",
    "    #resultsDF['Colours'] = resultsDF['Colours'].replace({' ': ', '}, regex=True)\n",
    "    resultsDF['Text'] = resultsDF['Text'].apply(regex_text)\n",
    "    resultsDF = resultsDF.sort_values(by=['Similarity'],ascending=False)\n",
    "    return resultsDF.style.set_properties(subset=['Text'], **{'width': '350px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like anime\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_9e071eee_16fa_11ea_b578_e94b89302d9frow0_col6 {\n",
       "            width:  350px;\n",
       "        }    #T_9e071eee_16fa_11ea_b578_e94b89302d9frow1_col6 {\n",
       "            width:  350px;\n",
       "        }    #T_9e071eee_16fa_11ea_b578_e94b89302d9frow2_col6 {\n",
       "            width:  350px;\n",
       "        }</style><table id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Website</th>        <th class=\"col_heading level0 col1\" >BackColor</th>        <th class=\"col_heading level0 col2\" >LinkColor</th>        <th class=\"col_heading level0 col3\" >TextColor</th>        <th class=\"col_heading level0 col4\" >TitleFont</th>        <th class=\"col_heading level0 col5\" >BodyFont</th>        <th class=\"col_heading level0 col6\" >Text</th>        <th class=\"col_heading level0 col7\" >Similarity</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9flevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow0_col0\" class=\"data row0 col0\" >https://residentevil2remake.tumblr.com/</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow0_col1\" class=\"data row0 col1\" >#000000</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow0_col2\" class=\"data row0 col2\" >#992727</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow0_col3\" class=\"data row0 col3\" >#FFFFFF</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow0_col4\" class=\"data row0 col4\" >Garamond Classic FS</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow0_col5\" class=\"data row0 col5\" >Helvetica Neue</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow0_col6\" class=\"data row0 col6\" >...but are not they how same carlos with don like the jill looks good bright....</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow0_col7\" class=\"data row0 col7\" >0.53062</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9flevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow1_col0\" class=\"data row1 col0\" >https://mwagneto.tumblr.com/</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow1_col1\" class=\"data row1 col1\" >#050505</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow1_col2\" class=\"data row1 col2\" >#60c7ff</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow1_col3\" class=\"data row1 col3\" >#60c7ff</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow1_col4\" class=\"data row1 col4\" >Calluna</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow1_col5\" class=\"data row1 col5\" >Helvetica Neue</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow1_col6\" class=\"data row1 col6\" >...but kinda Tulio asshole throwing had emotionally feel like ngl Miguel....</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow1_col7\" class=\"data row1 col7\" >0.527802</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9flevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow2_col0\" class=\"data row2 col0\" >https://jaboncito.tumblr.com/</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow2_col1\" class=\"data row2 col1\" >#ffffff</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow2_col2\" class=\"data row2 col2\" >#ff8d8d</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow2_col3\" class=\"data row2 col3\" >#ff8d8d</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow2_col4\" class=\"data row2 col4\" >Typewriter FS</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow2_col5\" class=\"data row2 col5\" >Helvetica Neue</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow2_col6\" class=\"data row2 col6\" >...quick post think doodles here couple forgot redra them like about dgs....</td>\n",
       "                        <td id=\"T_9e071eee_16fa_11ea_b578_e94b89302d9frow2_col7\" class=\"data row2 col7\" >0.50471</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc3948150f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarityQuery('I will talk about some cool topics in programming')\n",
    "similarityQuery('I like anime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def generateResult(description):\n",
    "    df = similarityQuery(description)\n",
    "    dict = {}\n",
    "    aF = [ast.literal_eval(df.iloc[0]['Fonts']), ast.literal_eval(df.iloc[1]['Fonts']), ast.literal_eval(df.iloc[2]['Fonts'])]\n",
    "    aC = [ast.literal_eval(df.iloc[0]['Colours']), ast.literal_eval(df.iloc[1]['Colours']), ast.literal_eval(df.iloc[2]['Colours'])]\n",
    "    aT = [df.iloc[0]['Text'], df.iloc[1]['Text'], df.iloc[2]['Text']]\n",
    "    \n",
    "    font_size = []\n",
    "    for i in range(len(aF)):\n",
    "        font_size.append(len(aF[i]))\n",
    "        for j in range(len(aF[i])):\n",
    "            aF[i][j][1] = int(aF[i][j][1])\n",
    "    \n",
    "    color_size = []\n",
    "    for i in range(len(aC)):\n",
    "        color_size.append(len(aC[i]))\n",
    "        for j in range(len(aC[i])):\n",
    "            if (' ' in aC[i][j][0]) or (',' in aC[i][j][0]):\n",
    "                aC[i][j][0] = aC[i][j][0].replace(' ','')\n",
    "                aC[i][j][0] = aC[i][j][0].replace(',','')\n",
    "    \n",
    "    dict['f_size'] = font_size\n",
    "    dict['c_size'] = color_size\n",
    "    dict['fonts'] = aF\n",
    "    dict['colors'] = aC\n",
    "    dict['texts'] = aT\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big  and machine learning\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: Timestamp('2019-11-25 16:00:24')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e0a439be01e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"big data and machine learning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-bb3fc293e16c>\u001b[0m in \u001b[0;36mgenerateResult\u001b[0;34m(description)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarityQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fonts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fonts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fonts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0maC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Colours'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Colours'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Colours'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ast.py\u001b[0m in \u001b[0;36m_convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ast.py\u001b[0m in \u001b[0;36m_convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'malformed node or string: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnaryOp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUAdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: Timestamp('2019-11-25 16:00:24')"
     ]
    }
   ],
   "source": [
    "generateResult(\"big data and machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
