{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "#model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GoogleNews-vectors-negative300-SLIM.bin.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3d81cf5e23d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GoogleNews-vectors-negative300-SLIM.bin.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\projects\\piesparkdayum\\webcrawlstylecreator\\app-env\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\piesparkdayum\\webcrawlstylecreator\\app-env\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading projection weights from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# throws for invalid file format\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\piesparkdayum\\webcrawlstylecreator\\app-env\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[0mbinary_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m     \u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mignore_ext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mdecompressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\piesparkdayum\\webcrawlstylecreator\\app-env\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[1;34m(uri, mode, transport_params)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m             \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msmart_open_ssh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCHEMES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GoogleNews-vectors-negative300-SLIM.bin.gz'"
     ]
    }
   ],
   "source": [
    "model2 = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300-SLIM.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.similarities import WmdSimilarity\n",
    "import pickle\n",
    "# from cassandra.cluster import Cluster\n",
    "# from cassandra.query import BatchStatement\n",
    "# from cassandra import ConsistencyLevel\n",
    "# cluster = Cluster(['127.0.0.1'])#Cluster(['199.60.17.32','199.60.17.65'])\n",
    "# session = cluster.connect('mcanute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/matt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "stop_words = stopwords.words('english')\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\young\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')  # Download data for tokenizer.\n",
    "\n",
    "def preprocess(doc):\n",
    "    doc = doc.lower()  # Lower the text.\n",
    "    doc = word_tokenize(doc)  # Split into words.\n",
    "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
    "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('websites/ParsedWebsitesCleanSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"SELECT * from Blogs;\"\n",
    "# data = pd.DataFrame(list(session.execute(query)))\n",
    "data = pd.read_csv('ParsedBlogsCleanSamplev2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(648, 10)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna() # !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['body_text'].apply(len)>2] ## !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_corpus = data['body_text'].apply(preprocess).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = WmdSimilarity(wmd_corpus, model2, num_best=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(instance,open('WordMoverDistance-BlogInstanceSLIM.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = pickle.load(open('WordMoverDistance-BlogInstanceSLIM.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_text(val):\n",
    "    if val:\n",
    "        reg = re.compile(r'\\b\\w{3,20}\\b')\n",
    "        temp = reg.findall(val)\n",
    "        temp_set = set(temp)\n",
    "        temp_list = list(temp_set)\n",
    "        if len(temp_list) < 20:\n",
    "            temp2 = temp_list\n",
    "        elif len(temp_list) < 50:\n",
    "            temp2 = temp_list[10:]\n",
    "        elif len(temp_list) < 100:\n",
    "            temp2 = temp_list[30:]\n",
    "        else:\n",
    "            temp2 = temp_list[50:100]\n",
    "        result = \" \".join(temp2) \n",
    "        return (\"...\" + result + \"....\")\n",
    "    else:\n",
    "        return \"Empty string found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>website</th>\n",
       "      <th>back_color</th>\n",
       "      <th>body_font</th>\n",
       "      <th>body_text</th>\n",
       "      <th>last_update</th>\n",
       "      <th>link_color</th>\n",
       "      <th>text_color</th>\n",
       "      <th>title_font</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://lebleurenard.tumblr.com/</td>\n",
       "      <td>#4ad791</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>Please send me asks ❤️ Moodboard for nights a...</td>\n",
       "      <td>2019-12-03 21:34:55</td>\n",
       "      <td>#A77DC2</td>\n",
       "      <td>#444444</td>\n",
       "      <td>Clarendon Text Pro</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://eboyanti.tumblr.com/</td>\n",
       "      <td>#FFD3EB</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>i always laugh at how obnoxiously tall yukhei...</td>\n",
       "      <td>2019-12-04 05:44:36</td>\n",
       "      <td>#FFFFFF</td>\n",
       "      <td>#FFB8E3</td>\n",
       "      <td>Caslon FS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://trashout.tumblr.com/</td>\n",
       "      <td>#958383</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>fe doobliedoos from twitter again then and no...</td>\n",
       "      <td>2019-11-02 14:19:26</td>\n",
       "      <td>#6AB3DF</td>\n",
       "      <td>#444444</td>\n",
       "      <td>Gibson</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://geminihurt.tumblr.com/</td>\n",
       "      <td>#CA2287</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>Seeing their split reflection on a broken gla...</td>\n",
       "      <td>2019-12-01 22:00:32</td>\n",
       "      <td>#000000</td>\n",
       "      <td>#8d8eb6</td>\n",
       "      <td>Clearface FS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           website back_color       body_font  \\\n",
       "0           0  https://lebleurenard.tumblr.com/    #4ad791  Helvetica Neue   \n",
       "1           1      https://eboyanti.tumblr.com/    #FFD3EB  Helvetica Neue   \n",
       "2           2      https://trashout.tumblr.com/    #958383  Helvetica Neue   \n",
       "3           4    https://geminihurt.tumblr.com/    #CA2287  Helvetica Neue   \n",
       "\n",
       "                                           body_text          last_update  \\\n",
       "0   Please send me asks ❤️ Moodboard for nights a...  2019-12-03 21:34:55   \n",
       "1   i always laugh at how obnoxiously tall yukhei...  2019-12-04 05:44:36   \n",
       "2   fe doobliedoos from twitter again then and no...  2019-11-02 14:19:26   \n",
       "3   Seeing their split reflection on a broken gla...  2019-12-01 22:00:32   \n",
       "\n",
       "  link_color text_color          title_font title_text  \n",
       "0    #A77DC2    #444444  Clarendon Text Pro        NaN  \n",
       "1    #FFFFFF    #FFB8E3           Caslon FS             \n",
       "2    #6AB3DF    #444444              Gibson        NaN  \n",
       "3    #000000    #8d8eb6        Clearface FS        NaN  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityQuery(description):  # !!!\n",
    "    description = description.replace('data', '')\n",
    "    query = preprocess(description)\n",
    "    sims = instance[query]  # A query is simply a \"look-up\" in the similarity class.\n",
    "\n",
    "    # Print the query and the retrieved documents, together with their similarities.\n",
    "    results = []\n",
    "    for i in range(4):\n",
    "\n",
    "        row = []\n",
    "        row.append(documents[sims[i][0]][1]) # Website\n",
    "        row.append(documents[sims[i][0]][2]) # Back_Color\n",
    "        row.append(documents[sims[i][0]][6]) # Link_Color\n",
    "        row.append(documents[sims[i][0]][7]) # Text_Color\n",
    "        row.append(documents[sims[i][0]][8]) # Title_Font\n",
    "        row.append(documents[sims[i][0]][3]) # Body_Font\n",
    "        \n",
    "        row.append(documents[sims[i][0]][4]) # Text\n",
    "        \n",
    "        row.append(sims[i][1])    # Similarity\n",
    "\n",
    "\n",
    "        results.append(row)\n",
    "    resultsDF = pd.DataFrame(results)\n",
    "\n",
    "    resultsDF.columns = ['Website','BackColor','LinkColor','TextColor','TitleFont','BodyFont','Text','Similarity']\n",
    "    #resultsDF['Fonts'] = resultsDF['Fonts'].replace({'\\\" \\'': '\\\", \\'', \"\\' \\'\": \"\\', \\'\", '(\\r\\n)': ','}, regex=True)\n",
    "    #resultsDF['Colours'] = resultsDF['Colours'].replace({' ': ', '}, regex=True)\n",
    "    resultsDF['Text'] = resultsDF['Text'].apply(regex_text)\n",
    "    resultsDF = resultsDF.sort_values(by=['Similarity'],ascending=False)\n",
    "    return resultsDF#.style.set_properties(subset=['Text'], **{'width': '350px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big  and machine learning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_149269b4_1704_11ea_a0f1_c799465cc254row0_col6 {\n",
       "            width:  350px;\n",
       "        }    #T_149269b4_1704_11ea_a0f1_c799465cc254row1_col6 {\n",
       "            width:  350px;\n",
       "        }    #T_149269b4_1704_11ea_a0f1_c799465cc254row2_col6 {\n",
       "            width:  350px;\n",
       "        }    #T_149269b4_1704_11ea_a0f1_c799465cc254row3_col6 {\n",
       "            width:  350px;\n",
       "        }</style><table id=\"T_149269b4_1704_11ea_a0f1_c799465cc254\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Website</th>        <th class=\"col_heading level0 col1\" >BackColor</th>        <th class=\"col_heading level0 col2\" >LinkColor</th>        <th class=\"col_heading level0 col3\" >TextColor</th>        <th class=\"col_heading level0 col4\" >TitleFont</th>        <th class=\"col_heading level0 col5\" >BodyFont</th>        <th class=\"col_heading level0 col6\" >Text</th>        <th class=\"col_heading level0 col7\" >Similarity</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_149269b4_1704_11ea_a0f1_c799465cc254level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row0_col0\" class=\"data row0 col0\" >https://masutrout.tumblr.com/</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row0_col1\" class=\"data row0 col1\" >#FAFAFA</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row0_col2\" class=\"data row0 col2\" >#529ECC</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row0_col3\" class=\"data row0 col3\" >#444444</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row0_col4\" class=\"data row0 col4\" >Gibson</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row0_col5\" class=\"data row0 col5\" >Helvetica Neue</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row0_col6\" class=\"data row0 col6\" >...machine softer....</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row0_col7\" class=\"data row0 col7\" >0.530816</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_149269b4_1704_11ea_a0f1_c799465cc254level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row1_col0\" class=\"data row1 col0\" >https://pencilshaevings.tumblr.com/</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row1_col1\" class=\"data row1 col1\" >#ec5868</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row1_col2\" class=\"data row1 col2\" >#fce7aa</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row1_col3\" class=\"data row1 col3\" >#fce7aa</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row1_col4\" class=\"data row1 col4\" >SimHei</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row1_col5\" class=\"data row1 col5\" >Helvetica Neue</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row1_col6\" class=\"data row1 col6\" >...MAGICAL cheeks hard have glasses bigger for big CHET work suizidale commission volume....</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row1_col7\" class=\"data row1 col7\" >0.480309</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_149269b4_1704_11ea_a0f1_c799465cc254level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row2_col0\" class=\"data row2 col0\" >https://hope-for-olicity.tumblr.com/</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row2_col1\" class=\"data row2 col1\" >#847d81</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row2_col2\" class=\"data row2 col2\" >#03131d</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row2_col3\" class=\"data row2 col3\" >#444444</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row2_col4\" class=\"data row2 col4\" >Georgia</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row2_col5\" class=\"data row2 col5\" >Helvetica Neue</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row2_col6\" class=\"data row2 col6\" >...should kill will you this Big Bad Your inability Barry realize Psst bite type the....</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row2_col7\" class=\"data row2 col7\" >0.46983</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_149269b4_1704_11ea_a0f1_c799465cc254level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row3_col0\" class=\"data row3 col0\" >https://ellanmwebb2.tumblr.com/</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row3_col1\" class=\"data row3 col1\" >#FAFAFA</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row3_col2\" class=\"data row3 col2\" >#529ECC</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row3_col3\" class=\"data row3 col3\" >#444444</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row3_col4\" class=\"data row3 col4\" >Gibson</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row3_col5\" class=\"data row3 col5\" >Helvetica Neue</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row3_col6\" class=\"data row3 col6\" >...Draw best Creating for here new some from prints Learning desk time November stay the Mega....</td>\n",
       "                        <td id=\"T_149269b4_1704_11ea_a0f1_c799465cc254row3_col7\" class=\"data row3 col7\" >0.469686</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19ccb7b4128>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarityQuery('I will talk about some cool topics in programming')\n",
    "# similarityQuery('i like anime')\n",
    "similarityQuery('big data and machine learning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def generateResult(description):\n",
    "    df = similarityQuery(description)\n",
    "    dict = {}\n",
    "    aBC = [df.iloc[0]['BackColor'], df.iloc[1]['BackColor'], df.iloc[2]['BackColor'], df.iloc[3]['BackColor']]\n",
    "    aLC = [df.iloc[0]['LinkColor'], df.iloc[1]['LinkColor'], df.iloc[2]['LinkColor'], df.iloc[3]['LinkColor']]\n",
    "    aTC = [df.iloc[0]['TextColor'], df.iloc[1]['TextColor'], df.iloc[2]['TextColor'], df.iloc[3]['TextColor']]\n",
    "    aTF = [df.iloc[0]['TitleFont'], df.iloc[1]['TitleFont'], df.iloc[2]['TitleFont'], df.iloc[3]['TitleFont']]\n",
    "    aBF = [df.iloc[0]['BodyFont'], df.iloc[1]['BodyFont'], df.iloc[2]['BodyFont'], df.iloc[3]['BodyFont']]\n",
    "    \n",
    "    dict['back_color'] = aBC\n",
    "    dict['link_color'] = aLC\n",
    "    dict['text_color'] = aTC\n",
    "    dict['title_font'] = aTF\n",
    "    dict['body_font'] = aBF\n",
    "    \n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 316 is out of bounds for axis 0 with size 215",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-f09592541818>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i will talk about cool tricks in machine learning and big data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-119-98c53e8029d8>\u001b[0m in \u001b[0;36mgenerateResult\u001b[1;34m(description)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarityQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0maBC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BackColor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BackColor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BackColor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BackColor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-117-8297bd6f48be>\u001b[0m in \u001b[0;36msimilarityQuery\u001b[1;34m(description)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Website\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Back_Color\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Link_Color\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 316 is out of bounds for axis 0 with size 215"
     ]
    }
   ],
   "source": [
    "generateResult(\"i will talk about cool tricks in machine learning and big data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
