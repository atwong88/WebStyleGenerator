{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "#model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GoogleNews-vectors-negative300-SLIM.bin.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3d81cf5e23d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GoogleNews-vectors-negative300-SLIM.bin.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\projects\\piesparkdayum\\webcrawlstylecreator\\app-env\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\piesparkdayum\\webcrawlstylecreator\\app-env\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading projection weights from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# throws for invalid file format\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\piesparkdayum\\webcrawlstylecreator\\app-env\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[0mbinary_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m     \u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mignore_ext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mdecompressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\piesparkdayum\\webcrawlstylecreator\\app-env\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[1;34m(uri, mode, transport_params)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m             \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msmart_open_ssh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCHEMES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GoogleNews-vectors-negative300-SLIM.bin.gz'"
     ]
    }
   ],
   "source": [
    "model2 = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300-SLIM.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.similarities import WmdSimilarity\n",
    "import pickle\n",
    "# from cassandra.cluster import Cluster\n",
    "# from cassandra.query import BatchStatement\n",
    "# from cassandra import ConsistencyLevel\n",
    "# cluster = Cluster(['127.0.0.1'])#Cluster(['199.60.17.32','199.60.17.65'])\n",
    "# session = cluster.connect('mcanute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\young\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "stop_words = stopwords.words('english')\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\young\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')  # Download data for tokenizer.\n",
    "\n",
    "def preprocess(doc):\n",
    "    doc = doc.lower()  # Lower the text.\n",
    "    doc = word_tokenize(doc)  # Split into words.\n",
    "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
    "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('websites/ParsedWebsitesCleanSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"SELECT * from Blogs;\"\n",
    "# data = pd.DataFrame(list(session.execute(query)))\n",
    "data = pd.read_csv('ParsedBlogsCleanSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(648, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna() # !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['body_text'].apply(len)>2] ## !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(648, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_corpus = data['body_text'].apply(preprocess).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = WmdSimilarity(wmd_corpus, model2, num_best=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(instance,open('WordMoverDistance-BlogInstanceSLIM.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = pickle.load(open('WordMoverDistance-BlogInstanceSLIM.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_text(val):\n",
    "    if val:\n",
    "        reg = re.compile(r'\\b\\w{3,20}\\b')\n",
    "        temp = reg.findall(val)\n",
    "        temp_set = set(temp)\n",
    "        temp_list = list(temp_set)\n",
    "        if len(temp_list) < 20:\n",
    "            temp2 = temp_list\n",
    "        elif len(temp_list) < 50:\n",
    "            temp2 = temp_list[10:]\n",
    "        elif len(temp_list) < 100:\n",
    "            temp2 = temp_list[30:]\n",
    "        else:\n",
    "            temp2 = temp_list[50:100]\n",
    "        result = \" \".join(temp2) \n",
    "        return (\"...\" + result + \"....\")\n",
    "    else:\n",
    "        return \"Empty string found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>website</th>\n",
       "      <th>back_color</th>\n",
       "      <th>body_font</th>\n",
       "      <th>body_text</th>\n",
       "      <th>last_update</th>\n",
       "      <th>link_color</th>\n",
       "      <th>text_color</th>\n",
       "      <th>title_font</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://lebleurenard.tumblr.com/</td>\n",
       "      <td>#4ad791</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>Please send me asks ❤️ Moodboard for nights a...</td>\n",
       "      <td>2019-12-03 21:34:55</td>\n",
       "      <td>#A77DC2</td>\n",
       "      <td>#444444</td>\n",
       "      <td>Clarendon Text Pro</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://eboyanti.tumblr.com/</td>\n",
       "      <td>#FFD3EB</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>i always laugh at how obnoxiously tall yukhei...</td>\n",
       "      <td>2019-12-04 05:44:36</td>\n",
       "      <td>#FFFFFF</td>\n",
       "      <td>#FFB8E3</td>\n",
       "      <td>Caslon FS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://trashout.tumblr.com/</td>\n",
       "      <td>#958383</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>fe doobliedoos from twitter again then and no...</td>\n",
       "      <td>2019-11-02 14:19:26</td>\n",
       "      <td>#6AB3DF</td>\n",
       "      <td>#444444</td>\n",
       "      <td>Gibson</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://geminihurt.tumblr.com/</td>\n",
       "      <td>#CA2287</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>Seeing their split reflection on a broken gla...</td>\n",
       "      <td>2019-12-01 22:00:32</td>\n",
       "      <td>#000000</td>\n",
       "      <td>#8d8eb6</td>\n",
       "      <td>Clearface FS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           website back_color       body_font  \\\n",
       "0           0  https://lebleurenard.tumblr.com/    #4ad791  Helvetica Neue   \n",
       "1           1      https://eboyanti.tumblr.com/    #FFD3EB  Helvetica Neue   \n",
       "2           2      https://trashout.tumblr.com/    #958383  Helvetica Neue   \n",
       "3           4    https://geminihurt.tumblr.com/    #CA2287  Helvetica Neue   \n",
       "\n",
       "                                           body_text          last_update  \\\n",
       "0   Please send me asks ❤️ Moodboard for nights a...  2019-12-03 21:34:55   \n",
       "1   i always laugh at how obnoxiously tall yukhei...  2019-12-04 05:44:36   \n",
       "2   fe doobliedoos from twitter again then and no...  2019-11-02 14:19:26   \n",
       "3   Seeing their split reflection on a broken gla...  2019-12-01 22:00:32   \n",
       "\n",
       "  link_color text_color          title_font title_text  \n",
       "0    #A77DC2    #444444  Clarendon Text Pro        NaN  \n",
       "1    #FFFFFF    #FFB8E3           Caslon FS             \n",
       "2    #6AB3DF    #444444              Gibson        NaN  \n",
       "3    #000000    #8d8eb6        Clearface FS        NaN  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityQuery(description):  # !!!\n",
    "    description = description.replace('data', '')\n",
    "    query = preprocess(description)\n",
    "    sims = instance[query]  # A query is simply a \"look-up\" in the similarity class.\n",
    "\n",
    "    # Print the query and the retrieved documents, together with their similarities.\n",
    "    results = []\n",
    "    for i in range(4):\n",
    "\n",
    "        row = []\n",
    "        try:\n",
    "            row.append(documents[sims[i][0]][1]) # Website\n",
    "            row.append(documents[sims[i][0]][2]) # Back_Color\n",
    "            row.append(documents[sims[i][0]][6]) # Link_Color\n",
    "            row.append(documents[sims[i][0]][7]) # Text_Color\n",
    "            row.append(documents[sims[i][0]][8]) # Title_Font\n",
    "            row.append(documents[sims[i][0]][3]) # Body_Font\n",
    "            row.append(documents[sims[i][0]][4]) # Text\n",
    "            row.append(sims[i][1])    # Similarity\n",
    "            results.append(row)\n",
    "        except IndexError:\n",
    "            row.append(\"sampleBlog\") # Website\n",
    "            row.append('#ec5868') # Back_Color\n",
    "            row.append(\"#444444\") # Link_Color\n",
    "            row.append(\"#444444\") # Text_Color\n",
    "            row.append(\"Helvetica Neue\") # Title_Font\n",
    "            row.append(\"Helvetica Neue\") # Body_Font\n",
    "            row.append(\"sampleText\") # Text\n",
    "            row.append(\"0.0\")    # Similarity\n",
    "            results.append(row)\n",
    "            break\n",
    "        \n",
    "    resultsDF = pd.DataFrame(results)\n",
    "\n",
    "    resultsDF.columns = ['Website','BackColor','LinkColor','TextColor','TitleFont','BodyFont','Text','Similarity']\n",
    "    #resultsDF['Fonts'] = resultsDF['Fonts'].replace({'\\\" \\'': '\\\", \\'', \"\\' \\'\": \"\\', \\'\", '(\\r\\n)': ','}, regex=True)\n",
    "    #resultsDF['Colours'] = resultsDF['Colours'].replace({' ': ', '}, regex=True)\n",
    "    resultsDF['Text'] = resultsDF['Text'].apply(regex_text)\n",
    "    resultsDF = resultsDF.sort_values(by=['Similarity'],ascending=False)\n",
    "    return resultsDF#.style.set_properties(subset=['Text'], **{'width': '350px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "      <th>BackColor</th>\n",
       "      <th>LinkColor</th>\n",
       "      <th>TextColor</th>\n",
       "      <th>TitleFont</th>\n",
       "      <th>BodyFont</th>\n",
       "      <th>Text</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://masutrout.tumblr.com/</td>\n",
       "      <td>#FAFAFA</td>\n",
       "      <td>#529ECC</td>\n",
       "      <td>#444444</td>\n",
       "      <td>Gibson</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>...machine softer....</td>\n",
       "      <td>0.530816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://pencilshaevings.tumblr.com/</td>\n",
       "      <td>#ec5868</td>\n",
       "      <td>#fce7aa</td>\n",
       "      <td>#fce7aa</td>\n",
       "      <td>SimHei</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>...hard big for have glasses suizidale CHET MA...</td>\n",
       "      <td>0.480309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://hope-for-olicity.tumblr.com/</td>\n",
       "      <td>#847d81</td>\n",
       "      <td>#03131d</td>\n",
       "      <td>#444444</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>...should Your inability realize will Bad type...</td>\n",
       "      <td>0.469830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://ellanmwebb2.tumblr.com/</td>\n",
       "      <td>#FAFAFA</td>\n",
       "      <td>#529ECC</td>\n",
       "      <td>#444444</td>\n",
       "      <td>Gibson</td>\n",
       "      <td>Helvetica Neue</td>\n",
       "      <td>...here for desk Draw new from Creating best p...</td>\n",
       "      <td>0.469686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Website BackColor LinkColor TextColor  \\\n",
       "0         https://masutrout.tumblr.com/   #FAFAFA   #529ECC   #444444   \n",
       "1   https://pencilshaevings.tumblr.com/   #ec5868   #fce7aa   #fce7aa   \n",
       "2  https://hope-for-olicity.tumblr.com/   #847d81   #03131d   #444444   \n",
       "3       https://ellanmwebb2.tumblr.com/   #FAFAFA   #529ECC   #444444   \n",
       "\n",
       "  TitleFont        BodyFont  \\\n",
       "0    Gibson  Helvetica Neue   \n",
       "1    SimHei  Helvetica Neue   \n",
       "2   Georgia  Helvetica Neue   \n",
       "3    Gibson  Helvetica Neue   \n",
       "\n",
       "                                                Text  Similarity  \n",
       "0                              ...machine softer....    0.530816  \n",
       "1  ...hard big for have glasses suizidale CHET MA...    0.480309  \n",
       "2  ...should Your inability realize will Bad type...    0.469830  \n",
       "3  ...here for desk Draw new from Creating best p...    0.469686  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarityQuery('I will talk about some cool topics in programming')\n",
    "# similarityQuery('i like anime')\n",
    "similarityQuery('big data and machine learning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def generateResult(description):\n",
    "    df = similarityQuery(description)\n",
    "    dict = {}\n",
    "    try:\n",
    "        aBC = [df.iloc[0]['BackColor'], df.iloc[1]['BackColor'], df.iloc[2]['BackColor'], df.iloc[3]['BackColor']]\n",
    "        aLC = [df.iloc[0]['LinkColor'], df.iloc[1]['LinkColor'], df.iloc[2]['LinkColor'], df.iloc[3]['LinkColor']]\n",
    "        aTC = [df.iloc[0]['TextColor'], df.iloc[1]['TextColor'], df.iloc[2]['TextColor'], df.iloc[3]['TextColor']]\n",
    "        aTF = [df.iloc[0]['TitleFont'], df.iloc[1]['TitleFont'], df.iloc[2]['TitleFont'], df.iloc[3]['TitleFont']]\n",
    "        aBF = [df.iloc[0]['BodyFont'], df.iloc[1]['BodyFont'], df.iloc[2]['BodyFont'], df.iloc[3]['BodyFont']]\n",
    "    except:\n",
    "        aBC = [df.iloc[0]['BackColor']]\n",
    "        aLC = [df.iloc[0]['LinkColor']]\n",
    "        aTC = [df.iloc[0]['TextColor']]\n",
    "        aTF = [df.iloc[0]['TitleFont']]\n",
    "        aBF = [df.iloc[0]['BodyFont']]\n",
    "    \n",
    "    \n",
    "    dict['first'] = len(aBC)\n",
    "    dict['back_color'] = aBC\n",
    "    dict['link_color'] = aLC\n",
    "    dict['text_color'] = aTC\n",
    "    dict['title_font'] = aTF\n",
    "    dict['body_font'] = aBF\n",
    "    \n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': 1,\n",
       " 'back_color': ['#ec5868'],\n",
       " 'link_color': ['#444444'],\n",
       " 'text_color': ['#444444'],\n",
       " 'title_font': ['Helvetica Neue'],\n",
       " 'body_font': ['Helvetica Neue']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateResult(\"rehsgfew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
