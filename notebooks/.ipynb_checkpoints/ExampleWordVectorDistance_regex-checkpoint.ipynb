{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.similarities import WmdSimilarity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Adriena\n",
      "[nltk_data]     Wong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "stop_words = stopwords.words('english')\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\young\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')  # Download data for tokenizer.\n",
    "\n",
    "def preprocess(doc):\n",
    "    doc = doc.lower()  # Lower the text.\n",
    "    doc = word_tokenize(doc)  # Split into words.\n",
    "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
    "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('websites/ParsedWebsitesCleanSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_corpus = data['text'].apply(preprocess).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = pickle.load(open('WordMoverDistance-Instance.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityQuery(description):   \n",
    "    query = preprocess(description)\n",
    "    sims = instance[query]  # A query is simply a \"look-up\" in the similarity class.\n",
    "\n",
    "    # Print the query and the retrieved documents, together with their similarities.\n",
    "    results = []\n",
    "    print(description)\n",
    "    for i in range(3):\n",
    "\n",
    "        row = []\n",
    "        row.append(documents[sims[i][0]][0]) # WebsiteKey\n",
    "        row.append(documents[sims[i][0]][2]) # Website\n",
    "        row.append(documents[sims[i][0]][3]) # Colors\n",
    "        row.append(documents[sims[i][0]][4]) # Fonts\n",
    "        \n",
    "        row.append(documents[sims[i][0]][5]) # Text\n",
    "        \n",
    "        row.append(sims[i][1])    # Similarity\n",
    "\n",
    "\n",
    "        results.append(row)\n",
    "    resultsDF = pd.DataFrame(results)\n",
    "\n",
    "    resultsDF.columns = ['WebsiteKey','Website','Colours','Fonts','Text','Similarity']\n",
    "    resultsDF['Fonts'] = resultsDF['Fonts'].replace({'\\\" \\'': '\\\", \\'', \"\\' \\'\": \"\\', \\'\", '\\r\\n': ','}, regex=True)\n",
    "    resultsDF['Colours'] = resultsDF['Colours'].replace({' ': ', '}, regex=True)\n",
    "    resultsDF = resultsDF.sort_values(by=['Similarity'],ascending=False)\n",
    "    return resultsDF.style.set_properties(subset=['Text'], **{'width': '350px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some sample random text to test similarity query woohoo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow0_col4 {\n",
       "            width:  350px;\n",
       "        }    #T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow1_col4 {\n",
       "            width:  350px;\n",
       "        }    #T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow2_col4 {\n",
       "            width:  350px;\n",
       "        }</style><table id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >WebsiteKey</th>        <th class=\"col_heading level0 col1\" >Website</th>        <th class=\"col_heading level0 col2\" >Colours</th>        <th class=\"col_heading level0 col3\" >Fonts</th>        <th class=\"col_heading level0 col4\" >Text</th>        <th class=\"col_heading level0 col5\" >Similarity</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49flevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow0_col0\" class=\"data row0 col0\" >960</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow0_col1\" class=\"data row0 col1\" >cricketcrowd.com</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow0_col2\" class=\"data row0 col2\" >[['#1087dd', 10]\r\n",
       ", ['#337ab7', 7]\r\n",
       ", ['#0d70b7', 7]]</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow0_col3\" class=\"data row0 col3\" >[['font-family:\"Helvetica Neue\",Helvetica,Arial,sans-serif', '3'], [\"font-family:'Glyphicons Halflings'\", '2'], ['font-family:inherit', '2']]</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow0_col4\" class=\"data row0 col4\" >and toggle get grouped for better mobile of links and & T & Match Time & White Analysis & The World My Play List end Cricket t oval test Dev miller One Day Close to Cricket name | Forgot password | New To Cricket Crowd ? Sign up for free video start video | maiden maiden Test century to leave on the ropes \" confirmed himself as the No with a first Test century as \" accident waiting to ton st Test ged Test A J ged in in Test col day night fight Bay by well are these ? this Feedback well P H ANew Canada New Kyle C col main v Test series v Test series v BAN Test series v T series v BAN T around the world \" My will to win is strong Pollard \" international captain about passing on his to the youngster \" He now a Test match cricketer \" b \" He now a Test match cricketer \" with concussion protocol after often that a batsman to play on after being that more \" ever \" the century in World Twenty history as West World Cup of all its very inception in the World Cup up many remarkable Triple century legendary since opener his way This for of the \" Feeling Lucky \" b Click for new random video only works when is turned bowler of all col a \"\" | a \"\" Match | | News | a \"\" a | Links | About Us | Help | Contact Us | privacy policy | disclaimer | col container footer</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow0_col5\" class=\"data row0 col5\" >0.45782</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49flevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow1_col0\" class=\"data row1 col0\" >959</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow1_col1\" class=\"data row1 col1\" >cricschedule.com</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow1_col2\" class=\"data row1 col2\" >[['#e9ecef', 12]\r\n",
       ", ['#E95420', 10]\r\n",
       ", ['#F0F0F0', 8]]</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow1_col3\" class=\"data row1 col3\" >[['font-family:\"Ubuntu\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif, \"Apple Color Emoji\", \"Segoe UI Emoji\", \"Segoe UI Symbol\"',  '3'], [\"font-family:'Open Sans', sans-serif\", '22'], ['font-family:sans-serif', '2']]</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow1_col4\" class=\"data row1 col4\" >b of West tour of West for Supreme Court the on conundrum with test match About Use All reserved</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow1_col5\" class=\"data row1 col5\" >0.456634</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49flevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow2_col0\" class=\"data row2 col0\" >234</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow2_col1\" class=\"data row2 col1\" >situbiosciences.com</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow2_col2\" class=\"data row2 col2\" >[['#a46497', 4]\r\n",
       ", ['#ebe9eb', 2]\r\n",
       ", ['#dfdcde', 2]]</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow2_col3\" class=\"data row2 col3\" >[['font-family: FontAwesome', '9'], [\"font-family:'MuseoSans_500'\", '7'], [\"font-family: 'MuseoSans_500'\", '61']]</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow2_col4\" class=\"data row2 col4\" >data \" center \" data \" right \" \" \" plus search class \"\" class \" \" MIL About c Quote Request Search Product Microbial Product Test Fate and Fate and Control Control can we help ? About Product Testing Foster \"\" c Copyright All radius radius bobo ** Add custom for this * Be sure to start your use when to override * web search engine to better unfamiliar with the of test let us know how it can be ? free to contact our laboratory owl</td>\n",
       "                        <td id=\"T_62d83d78_1161_11ea_b4d9_ae50b3dcb49frow2_col5\" class=\"data row2 col5\" >0.4556</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23a867bd588>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarityQuery('some sample random text to test similarity query woohoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
