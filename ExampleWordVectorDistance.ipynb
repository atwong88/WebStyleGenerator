{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.similarities import WmdSimilarity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\young\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "stop_words = stopwords.words('english')\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\young\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')  # Download data for tokenizer.\n",
    "\n",
    "def preprocess(doc):\n",
    "    doc = doc.lower()  # Lower the text.\n",
    "    doc = word_tokenize(doc)  # Split into words.\n",
    "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
    "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('websites/ParsedWebsitesCleanSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_corpus = data['text'].apply(preprocess).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = WmdSimilarity(wmd_corpus, model, num_best=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(instance,open('WordMoverDistance-Instance.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = pickle.load(open('WordMoverDistance-Instance.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_text(val):\n",
    "    if val:\n",
    "        reg = re.compile(r'\\b\\w{3,20}\\b')\n",
    "        temp = reg.findall(val)\n",
    "        temp_set = set(temp)\n",
    "        temp_list = list(temp_set)\n",
    "        if len(temp_list) < 20:\n",
    "            temp2 = temp_list\n",
    "        elif len(temp_list) < 50:\n",
    "            temp2 = temp_list[10:]\n",
    "        elif len(temp_list) < 100:\n",
    "            temp2 = temp_list[30:]\n",
    "        else:\n",
    "            temp2 = temp_list[50:100]\n",
    "        result = \" \".join(temp2) \n",
    "        return (\"...\" + result + \"....\")\n",
    "    else:\n",
    "        return \"Empty string found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityQuery(description):  \n",
    "    description = description.replace('data', '')\n",
    "    query = preprocess(description)\n",
    "    sims = instance[query]  # A query is simply a \"look-up\" in the similarity class.\n",
    "\n",
    "    # Print the query and the retrieved documents, together with their similarities.\n",
    "    results = []\n",
    "    print(description)\n",
    "    for i in range(3):\n",
    "\n",
    "        row = []\n",
    "        row.append(documents[sims[i][0]][0]) # WebsiteKey\n",
    "        row.append(documents[sims[i][0]][2]) # Website\n",
    "        row.append(documents[sims[i][0]][3]) # Colors\n",
    "        row.append(documents[sims[i][0]][4]) # Fonts\n",
    "        \n",
    "        row.append(documents[sims[i][0]][5]) # Text\n",
    "        \n",
    "        row.append(sims[i][1])    # Similarity\n",
    "\n",
    "\n",
    "        results.append(row)\n",
    "    resultsDF = pd.DataFrame(results)\n",
    "    #resultsDF.to_csv(description + '.csv')\n",
    "\n",
    "    resultsDF.columns = ['WebsiteKey','Website','Colours','Fonts','Text','Similarity']\n",
    "    resultsDF['Fonts'] = resultsDF['Fonts'].replace({'\\\" \\'': '\\\", \\'', \"\\' \\'\": \"\\', \\'\", '(\\r\\n)': ','}, regex=True)\n",
    "    resultsDF['Colours'] = resultsDF['Colours'].replace({' ': ', '}, regex=True)\n",
    "    resultsDF['Text'] = resultsDF['Text'].apply(regex_text)\n",
    "    resultsDF = resultsDF.sort_values(by=['Similarity'],ascending=False)\n",
    "    return resultsDF#.style.set_properties(subset=['Text'], **{'width': '350px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample text to run this new fancy function\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_cbe3a162_1616_11ea_a055_bf59d3dc315brow0_col4 {\n",
       "            width:  350px;\n",
       "        }    #T_cbe3a162_1616_11ea_a055_bf59d3dc315brow1_col4 {\n",
       "            width:  350px;\n",
       "        }    #T_cbe3a162_1616_11ea_a055_bf59d3dc315brow2_col4 {\n",
       "            width:  350px;\n",
       "        }</style>  \n",
       "<table id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315b\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >WebsiteKey</th> \n",
       "        <th class=\"col_heading level0 col1\" >Website</th> \n",
       "        <th class=\"col_heading level0 col2\" >Colours</th> \n",
       "        <th class=\"col_heading level0 col3\" >Fonts</th> \n",
       "        <th class=\"col_heading level0 col4\" >Text</th> \n",
       "        <th class=\"col_heading level0 col5\" >Similarity</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315blevel0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow0_col0\" class=\"data row0 col0\" >1195</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow0_col1\" class=\"data row0 col1\" >nervousrat.com</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow0_col2\" class=\"data row0 col2\" >[['#FFFFFF', 31]\r\n",
       ", ['#EEEEEE', 17]\r\n",
       ", ['#FFCC00', 10]]</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow0_col3\" class=\"data row0 col3\" >[['font-family:Monaco,\"Courier New\",Courier,monospace', '6'], [\"font-family: 'Nunito Sans'\", '4'], ['font-family:Monaco,\"Lucida Console\",monospace', '3']]</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow0_col4\" class=\"data row0 col4\" >...function media and enable your Powered platform....</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow0_col5\" class=\"data row0 col5\" >0.479205</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315blevel0_row1\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow1_col0\" class=\"data row1 col0\" >1116</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow1_col1\" class=\"data row1 col1\" >vintagecarriage.com</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow1_col2\" class=\"data row1 col2\" >[['#f1f1f1', 2]\r\n",
       ", ['#f3f3f3', 2]\r\n",
       ", ['#1f1f1f', 1]]</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow1_col3\" class=\"data row1 col3\" >[['font-family:inherit', '4'], ['font-family:inheri', '4'], ['font-family:dashicons', '4']]</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow1_col4\" class=\"data row1 col4\" >...for horse fanciful life special your vision offer Loading share thisLike transportation Powered come was windowLike stunningly now Carriage try what....</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow1_col5\" class=\"data row1 col5\" >0.466943</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315blevel0_row2\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow2_col0\" class=\"data row2 col0\" >4</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow2_col1\" class=\"data row2 col1\" >cryptosightings.com</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow2_col2\" class=\"data row2 col2\" >[['#f5f5f5', 4]\r\n",
       ", ['#ed702b', 2]]</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow2_col3\" class=\"data row2 col3\" >[[\"font-family:'Lora',serif\", '5'], [\"font-family:'Oswald',sans-serif\", '5'], ['font-family:dashicons', '2']]</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow2_col4\" class=\"data row2 col4\" >...the likely your hunt big foot sure considering success will always research what with more target frightening serious easy Champ much legend local make covering Travel mean footage into innovative search channel check all give one overcome about share episode audience infamous had fairly Search current try format many worthy....</td> \n",
       "        <td id=\"T_cbe3a162_1616_11ea_a055_bf59d3dc315brow2_col5\" class=\"data row2 col5\" >0.463796</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x241abf33e10>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarityQuery('I will talk about some cool topics in programming')\n",
    "similarityQuery('sample text to run this new fancy function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def generateResult(description):\n",
    "    df = similarityQuery(description)\n",
    "    dict = {}\n",
    "    aF = [ast.literal_eval(df.iloc[0]['Fonts']), ast.literal_eval(df.iloc[1]['Fonts']), ast.literal_eval(df.iloc[2]['Fonts'])]\n",
    "    aC = [ast.literal_eval(df.iloc[0]['Colours']), ast.literal_eval(df.iloc[1]['Colours']), ast.literal_eval(df.iloc[2]['Colours'])]\n",
    "    aT = [df.iloc[0]['Text'], df.iloc[1]['Text'], df.iloc[2]['Text']]\n",
    "    \n",
    "    font_size = []\n",
    "    for i in range(len(aF)):\n",
    "        font_size.append(len(aF[i]))\n",
    "        for j in range(len(aF[i])):\n",
    "            aF[i][j][1] = int(aF[i][j][1])\n",
    "    \n",
    "    color_size = []\n",
    "    for i in range(len(aC)):\n",
    "        color_size.append(len(aC[i]))\n",
    "        for j in range(len(aC[i])):\n",
    "            if (' ' in aC[i][j][0]) or (',' in aC[i][j][0]):\n",
    "                aC[i][j][0] = aC[i][j][0].replace(' ','')\n",
    "                aC[i][j][0] = aC[i][j][0].replace(',','')\n",
    "    \n",
    "    dict['f_size'] = font_size\n",
    "    dict['c_size'] = color_size\n",
    "    dict['fonts'] = aF\n",
    "    dict['colors'] = aC\n",
    "    dict['texts'] = aT\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big  and machine learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f_size': [3, 3, 3],\n",
       " 'c_size': [3, 3, 3],\n",
       " 'fonts': [[['font-family:icomoo', 7],\n",
       "   ['font-family:IcoMoon', 7],\n",
       "   ['font-family:DaxCondensedLight, Arial, Helvetica, sans-serif', 7]],\n",
       "  [['font-family:\"Lucida Grande\",\"Lucida Sans Unicode\",Tahoma,sans-serif', 8],\n",
       "   ['font-family:\"Lucida Grande\",\"Lucida Sans Unicode\",Tahoma,sans-serif !important',\n",
       "    7],\n",
       "   [\"font-family: 'FontAwesome'\", 2]],\n",
       "  [['font-family:Neue Frutiger W01,sans-serif', 8],\n",
       "   ['font-family:Droid Sans Mono W01,monospace', 7],\n",
       "   ['font-family:\"Neue Frutiger W01\"', 6]]],\n",
       " 'colors': [[['#ffffff', 22], ['#a0ce4e', 12], ['#f6f6f6', 9]],\n",
       "  [['#ffffff', 13], ['#ffffff', 7], ['#008ec', 7]],\n",
       "  [['#14b4c3', 15], ['#24273f', 12], ['#11182f', 11]]],\n",
       " 'texts': ['...Model Root Testing system aSkip inside fingerprinting Group climate tool molecular Liquid the sample any for Room lab growth Research Cabinet vision biological Saving environment TESTING advanced cooling heating Growth classification computer Search analytics SCIENCE distributed test....',\n",
       "  '...Hill with transparent more child media Permanent Ping browse Fall document social FREE all green Holiday Shuffleboard The Day radius Virtual PARTY bowl video Eve bookmark Here Contact Field you alpha available virtual premiere Home SLIDER world Happening Memory Gallery drawn Click Corporate Skeleton Big Event Roller for subject below....',\n",
       "  '...based been creator Code Available much code love really Copilot into search ready IDE all give within use one great myself Mac today Atom ranked through was documentation Being Holy try seamless many Kyle plethora you function its NEW Faster applied kite this just and Save cog Bret for past....']}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateResult(\"big data and machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
